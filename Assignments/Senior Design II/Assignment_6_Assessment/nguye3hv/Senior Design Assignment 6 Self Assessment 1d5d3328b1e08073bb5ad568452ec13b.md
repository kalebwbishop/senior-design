# Senior Design Assignment 6 Self Assessment

**Individual Assignment : Four Paragraphs**

Part A - Two Paragraphs: What was your individual contribution to this project? Did you apply and build upon the skills identified in your initial assessment from last Fall? What did you do and how did you do it? What did you learn and what competencies did you build? What were your successes, what were you obstacles?

One of my primary contributions to the project focused on developing the text processing module, where I implemented core components such as BM25 for lexical similarity and a MiniLM BERT model for text ranking. I was also responsible for training a Named Entity Recognition model for allergen detection and ensuring its integration into the recipe database pipeline. This involved preprocessing the data, cleaning mislabeled or infrequent classes, and designing a classification strategy to improve model accuracy. I conducted rigorous testing on the tokenizer output and NLP model predictions to ensure compatibility and data consistency between the model and the database. Furthermore, a lot of the work I did on this project built directly on the skills I identified in my fall assessment. I came in with experience in Python, data preprocessing, and a basic understanding of NLP—but this project pushed me to apply those skills in more complex, real-world ways. For example, training the BERT model and implementing BM25 helped me deepen my understanding of text ranking systems. I also gained hands-on experience working with tokenizers, modeling evaluation metrics, and integrating everything into an actual application, which provided valuable experiences.

Through this project, I gained a deeper understanding of model training pipelines, especially the importance of selecting appropriate architectures and optimizing training processes under computational constraints. I learned how to evaluate model performance using metrics such as F1-score, loss, precision, and recall, and how to fine-tune models based on those insights. One of the biggest challenges was the resource-consuming nature of model experimentation—finding the right architecture and hyperparameters often required a powerful GPU, which was sometimes a bottleneck. Furthermore, as each model training took at least 10 hours, getting the best model for the project was a time-consuming task. However, successfully integrating the trained models into our Android application and observing accurate predictions in real-world scenarios marked a significant success.

Part B – Two Paragraphs: What did your group accomplish? What did you learn about group work? What aspects of teamwork were successful and what aspects of teamwork were not successful? How did your efforts on the project compare to that of your teammates?  Do any team members deserve special recognition?

As a group, we successfully developed a full-stack Android application that detects food allergens based on text and image inputs. Our project combined several key components: a BERT-based recipe ranking model, a Named Entity Recognition (NER) model for allergen detection, and a YOLO image classifier—all integrated into a mobile interface. We also built a backend pipeline that connected user queries with a cleaned and structured recipe database. At the Expo, we demonstrated a working system that accurately returned allergen flags from both scanned meals and written descriptions, showing the practical impact of our efforts. One successful part of our teamwork was the clear division of roles, which helped us stay organized and efficient. Communication was solid, and we supported each other when someone ran into issues. On the other hand, as each model’s was trained on different platforms, our project was delayed near the end to ensure that not error when integration was present. To prevent similar issues in the future, we plan to implement a continuous integration and continuous delivery pipeline to meet deadlines.

In terms of effort, I feel that my contributions were well-aligned with the rest of the team in terms of both time and impact. I focused heavily on the machine learning and NLP components, putting in 117 hours across the semester to ensure the models were properly trained, evaluated, and integrated into the backend. Everyone played to their strengths, and the workload ended up being balanced overall. Kaleb deserves special recognition for building a clean and responsive front end that tied everything together, and Eric consistently went the extra mile with testing and documentation, helping us catch bugs early and stay organized. It was a strong, collaborative team, and each person brought something essential to the table.